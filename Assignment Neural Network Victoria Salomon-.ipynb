{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a855562-674d-4463-a7a3-8c86b2f7d29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 20:30:07.219825: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7c5f97-f217-4288-85d1-2252cc25df2a",
   "metadata": {},
   "source": [
    "# MNIST Digit Classification with a Feedforward Neural Network  \n",
    "**Student:** Victoria Salomon  \n",
    "**Framework:** TensorFlow / Keras  \n",
    "**Goal:** Train a simple feedforward neural network (FNN) to classify handwritten digits (0–9) from the MNIST dataset.\n",
    "\n",
    "This notebook covers:\n",
    "1. Data loading and preprocessing  \n",
    "2. Model definition  \n",
    "3. Training  \n",
    "4. Evaluation on test data  \n",
    "5. Single image prediction demo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42f7247-5b54-4724-a85a-604c2b61a2f3",
   "metadata": {},
   "source": [
    "## Imports and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b69cc4a-aba7-4662-bbaf-187c384a77b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ad0b348-6fce-41f5-b535-6394ba6bc9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 0s 0us/step\n",
      "Train images: (60000, 28, 28)\n",
      "Train labels: (60000,)\n",
      "Test images: (10000, 28, 28)\n",
      "Test labels: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset from Keras\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "print(\"Train images:\", x_train.shape)\n",
    "print(\"Train labels:\", y_train.shape)\n",
    "print(\"Test images:\", x_test.shape)\n",
    "print(\"Test labels:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29f84b2-aefa-43f9-bc54-4764c7a6d5f6",
   "metadata": {},
   "source": [
    "## Preprocessing (Code cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "528a0ccd-8f0d-4315-9bdd-180c1b3f3bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape after flatten: (60000, 784)\n",
      "y_train one-hot shape: (60000, 10)\n",
      "y_train one-hot shape: (60000, 10)\n",
      "y_test one-hot shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# 1. Normalize pixel values (0-255 → 0-1)\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# 2. Flatten 28x28 → 784 vector\n",
    "x_train = x_train.reshape((x_train.shape[0], 28 * 28))\n",
    "x_test = x_test.reshape((x_test.shape[0], 28 * 28))\n",
    "\n",
    "# 3. One-hot encode labels (e.g. \"3\" -> [0,0,0,1,0,0,0,0,0,0])\n",
    "num_classes = 10\n",
    "y_train_cat = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_cat = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(\"x_train shape after flatten:\", x_train.shape)\n",
    "print(\"y_train one-hot shape:\", y_train_cat.shape)\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train_cat = to_categorical(y_train, num_classes=10)\n",
    "y_test_cat = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "print(\"y_train one-hot shape:\", y_train_cat.shape)\n",
    "print(\"y_test one-hot shape:\", y_test_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662974ca-97db-4979-89f7-a144edd71995",
   "metadata": {},
   "source": [
    "## Define the Model (Code cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06520e70-9681-40ce-82bf-df6479f87910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2710 - accuracy: 0.9235 - val_loss: 0.1502 - val_accuracy: 0.9568\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.1187 - accuracy: 0.9643 - val_loss: 0.0904 - val_accuracy: 0.9752\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0823 - accuracy: 0.9761 - val_loss: 0.0849 - val_accuracy: 0.9752\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0613 - accuracy: 0.9819 - val_loss: 0.0842 - val_accuracy: 0.9763\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0467 - accuracy: 0.9860 - val_loss: 0.0724 - val_accuracy: 0.9768\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Define model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(784,)),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    x_train, y_train_cat,\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b23850-c8a6-4b79-a185-7ea0883a483e",
   "metadata": {},
   "source": [
    "## Compile the Model (Code cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f67d2fc0-1750-4183-993d-9052af3a26b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22b1bab-c02a-45f6-93b4-e59b0e1f085f",
   "metadata": {},
   "source": [
    "## Train the Model (Code cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84f5366-f0a0-470a-98b1-14fbcf0af4f4",
   "metadata": {},
   "source": [
    "### Model Summary \n",
    "Bellow is a summary of the model architecture showing the total parameters and layer connections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e90384a8-789f-4938-bcc7-66eda85c0801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2741 - accuracy: 0.9225 - val_loss: 0.1337 - val_accuracy: 0.9638\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.1214 - accuracy: 0.9644 - val_loss: 0.1093 - val_accuracy: 0.9685\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0846 - accuracy: 0.9745 - val_loss: 0.0891 - val_accuracy: 0.9750\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0637 - accuracy: 0.9805 - val_loss: 0.0801 - val_accuracy: 0.9778\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0488 - accuracy: 0.9855 - val_loss: 0.0770 - val_accuracy: 0.9810\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train_cat,\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078b0790-322d-41a3-a053-7bb1a8d3860f",
   "metadata": {},
   "source": [
    "## Evaluate on Test Set (Code cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcd4b1d6-c20f-49e5-bfd1-8d92d2ab9e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Loss: 0.07864340394735336\n",
      "Final Test Accuracy: 0.9758999943733215\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test_cat, verbose=0)\n",
    "\n",
    "print(\"Final Test Loss:\", test_loss)\n",
    "print(\"Final Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8307006-8c62-4d85-9187-0024c49574b5",
   "metadata": {},
   "source": [
    "## Single Prediction Demo (Code cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8ddac05-b9d1-4f74-81bf-cdffd747a027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 75ms/step\n",
      "Model prediction: 7\n",
      "True label: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pick a random index from test set\n",
    "i = random.randint(0, x_test.shape[0] - 1)\n",
    "\n",
    "sample_image = x_test[i]\n",
    "sample_label = y_test[i]\n",
    "\n",
    "sample_input = np.expand_dims(sample_image, axis=0)\n",
    "\n",
    "prediction = model.predict(sample_input)\n",
    "predicted_digit = np.argmax(prediction[0])\n",
    "\n",
    "print(\"Model prediction:\", predicted_digit)\n",
    "print(\"True label:\", sample_label)\n",
    "\n",
    "plt.imshow(sample_image.reshape(28, 28), cmap=\"gray\")\n",
    "plt.title(f\"Predicted: {predicted_digit}, True: {sample_label}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deff092a-bf77-479a-ab3a-bc495a31434b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 20:49:52.493149: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.12.0\n",
      "Matplotlib imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"Matplotlib imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7df0dd-9b81-49e2-853f-49b21d704505",
   "metadata": {},
   "source": [
    "## Save the model \n",
    "This let us use the model again in the future "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b1ef2d2-328f-45bd-b74d-3cde17bc85d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "model.save(\"mnist_model_victoria.h5\")\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92e70bf-3949-4de5-a946-509f73381ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfenv)",
   "language": "python",
   "name": "tfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
